{
    "model_name_or_path": "xlm-roberta-base",
    "output_dir": "xlm-roberta-base_lora-v2_ep30_mldbW-verses_bs512",
    "block_size": 512,
    "do_train": true,
    "do_eval": true,
    "per_device_train_batch_size": 32,
    "per_device_eval_batch_size": 32,
    "gradient_accumulation_steps": 2,
    "eval_accumulation_steps": 8,
    "evaluation_strategy": "epoch",
    "dataloader_num_workers": 1,
    "preprocessing_num_workers": 1,
    "learning_rate": 3e-4,
    "fp16": false,
    "num_train_epochs": 30,
    "logging_steps": 50,
    "report_to": "wandb",
    "wandb_project": "lyrics-peft",
    "save_steps": 100000000,
    "remove_unused_columns": false,
    "one_sample_per_line": true,
    "do_sentence_training": true,
    "do_auxiliary_training": false,
    "warmup_ratio": 0.1,
    "non_punctuation_sample_ratio": null,
    "prediction_loss_only": true,
    "use_auxiliary": false,
    "ddp_timeout": 3600,
    "use_subwords": true,
    "custom_punctuation_file": "punctuation_xlmr_unk.txt",
    "log_level": "warning",
    "adapter_config": "lora[r=16,alpha=32,intermediate_lora=True]",
    "weight_decay": 0.0,
    "auxiliary_remove_prob": 0.0,
    "text_path": "data/all_data_11_05-lyrics.pth",
    "skip_eval_loss": false,
    "shuffle": false,
    "train_adapter": true,
    "subsample": null
}