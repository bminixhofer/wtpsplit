{
    "model_name_or_path": "xlmr-12l-v3_lc0.1-mix2",
    "output_dir": "xlmr-12l-v4_lora_r8_a16_qkv-int-out_ep30_mldbW-verses_s1000",
    "block_size": 256,
    "eval_stride": 128,
    "do_train": true,
    "do_eval": true,
    "per_device_train_batch_size": 64,
    "per_device_eval_batch_size": 32,
    "gradient_accumulation_steps": 1,
    "eval_accumulation_steps": 8,
    "evaluation_strategy": "epoch",
    "dataloader_num_workers": 1,
    "preprocessing_num_workers": 1,
    "learning_rate": 3e-4,
    "fp16": false,
    "num_train_epochs": 30,
    "logging_steps": 50,
    "report_to": "wandb",
    "wandb_project": "lyrics-peft",
    "save_steps": 100000000,
    "remove_unused_columns": false,
    "one_sample_per_line": true,
    "do_sentence_training": true,
    "do_auxiliary_training": false,
    "warmup_ratio": 0.1,
    "non_punctuation_sample_ratio": null,
    "prediction_loss_only": true,
    "use_auxiliary": true,
    "ddp_timeout": 3600,
    "use_subwords": true,
    "custom_punctuation_file": "punctuation_xlmr_unk.txt",
    "log_level": "warning",
    "adapter_config": "lora[r=8,alpha=16,dropout=0.1,intermediate_lora=True,output_lora=True,attn_matrices=['q','k','v']]",
    "weight_decay": 0.0,
    "auxiliary_remove_prob": 0.0,
    "text_path": "data/mldbW_verses_strip_n_strip_single_f.pt",
    "skip_eval_loss": false,
    "shuffle": false,
    "train_adapter": true,
    "subsample": 1000
}