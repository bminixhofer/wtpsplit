{
    "af": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6541666666666667,
                "recall": 0.5401376146788991,
                "precision": 0.829225352112676,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001732774644781198,
                "deletion_rate": 0.006080463753504931
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.39312231340367326,
                "recall": 0.28841743119266056,
                "precision": 0.6171779141104294,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008268973158913126,
                "deletion_rate": 0.0016207187391469727
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5560791705937794,
                "recall": 0.5042735042735043,
                "precision": 0.6197478991596639,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005315261444422297,
                "deletion_rate": 0.0008748034460611698
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 1.0,
                "recall": 1.0,
                "precision": 1.0,
                "correct_pairwise": 1,
                "hallucination_rate": 0.00018659881255301102,
                "deletion_rate": 0.00044105173876166244
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.824468085106383,
                "recall": 0.8115183246073299,
                "precision": 0.8378378378378378,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000103978926937474,
                "deletion_rate": 0.0006065437404685984
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "am": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.36157024793388426,
                "recall": 0.2924791086350975,
                "precision": 0.4733994589720469,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006167437026502202,
                "deletion_rate": 0.018379235839509886
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2588066139468008,
                "recall": 0.20055710306406685,
                "precision": 0.364741641337386,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0058468306338732255,
                "deletion_rate": 0.041823635272945414
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2723404255319149,
                "recall": 0.2077922077922078,
                "precision": 0.3950617283950617,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009517897786054211,
                "deletion_rate": 0.0026070763500931097
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ar": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6222996515679442,
                "recall": 0.49832589285714285,
                "precision": 0.8283858998144712,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0022932761894020564,
                "deletion_rate": 0.0038158612003985036
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5267624020887728,
                "recall": 0.45033482142857145,
                "precision": 0.6344339622641509,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020925388822922546,
                "deletion_rate": 0.0016059019329219628
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5469962114378496,
                "recall": 0.5053333333333333,
                "precision": 0.5961462839166339,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020718876991506997,
                "deletion_rate": 0.0036568217536201335
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8012718600953895,
                "recall": 0.8235294117647058,
                "precision": 0.7801857585139319,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009616549551732494,
                "deletion_rate": 0.0052550278652774415
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6302943287867911,
                "recall": 0.7173202614379085,
                "precision": 0.5620998719590269,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004627320374789929,
                "deletion_rate": 0.014633996608166491
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9236058059587472,
                "recall": 0.893569844789357,
                "precision": 0.9557312252964427,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0018068496025843424,
                "deletion_rate": 0.004654006552111185
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5862068965517242,
                "recall": 0.565410199556541,
                "precision": 0.6085918854415274,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0019406997879430476,
                "deletion_rate": 0.002792714328991215
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "az": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.767934643860097,
                "recall": 0.8378830083565459,
                "precision": 0.708765315739868,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002711364412799809,
                "deletion_rate": 0.026913003161450906
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5803370786516855,
                "recall": 0.5754874651810585,
                "precision": 0.5852691218130311,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006443260528466683,
                "deletion_rate": 0.0012170603220437069
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6528469750889679,
                "recall": 0.6026609724047306,
                "precision": 0.7121506211180124,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0019517623643717766,
                "deletion_rate": 0.004123954030860103
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "be": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5447684391080617,
                "recall": 0.4493491794001132,
                "precision": 0.6916376306620209,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017500339812423543,
                "deletion_rate": 0.0030753024330569525
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33184221228141525,
                "recall": 0.23103057757644394,
                "precision": 0.5887445887445888,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002407618775859609,
                "deletion_rate": 0.001605079183906406
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.44803749267721155,
                "recall": 0.3446908238687579,
                "precision": 0.6398929049531459,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006434316353887399,
                "deletion_rate": 0.005379088471849866
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8809926677946983,
                "recall": 0.8059855521155831,
                "precision": 0.9713930348258707,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005452197618250514,
                "deletion_rate": 0.04075756851116744
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4756898817345597,
                "recall": 0.3735810113519092,
                "precision": 0.6546112115732369,
                "correct_pairwise": 0,
                "hallucination_rate": 0.003548722459914431,
                "deletion_rate": 0.015944260066376104
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "bg": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9463013698630138,
                "recall": 0.9610461880912632,
                "precision": 0.9320021586616298,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015263954729344022,
                "deletion_rate": 0.0008190414732818744
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5197662426950842,
                "recall": 0.42070116861435725,
                "precision": 0.6798561151079137,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010819830272060069,
                "deletion_rate": 0.0015903846905919621
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5563507457695137,
                "recall": 0.4622138252945099,
                "precision": 0.6986393415084832,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006081628135178799,
                "deletion_rate": 0.003760908687276214
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9734422880490297,
                "recall": 0.9492031872509961,
                "precision": 0.9989517819706499,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00046416097102475136,
                "deletion_rate": 0.00034812072826856356
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5866517106001121,
                "recall": 0.5209163346613546,
                "precision": 0.6713735558408216,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00046623947972456006,
                "deletion_rate": 0.006312165263963275
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "bn": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.799651061355045,
                "recall": 0.7681564245810056,
                "precision": 0.8338386901152214,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0019401151134967342,
                "deletion_rate": 0.005561663325357304
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.1542056074766355,
                "recall": 0.1106145251396648,
                "precision": 0.2544987146529563,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002852511640472293,
                "deletion_rate": 0.0027174344875808476
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.14964925954793454,
                "recall": 0.14358974358974358,
                "precision": 0.15624273424784935,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0036045709026765855,
                "deletion_rate": 0.010096407609749936
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9690721649484536,
                "recall": 0.94,
                "precision": 1.0,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006792452830188679,
                "deletion_rate": 0.0037735849056603774
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33802816901408445,
                "recall": 0.24,
                "precision": 0.5714285714285714,
                "correct_pairwise": 0,
                "hallucination_rate": 0.009149130832570906,
                "deletion_rate": 0.0
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ca": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9088888888888889,
                "recall": 0.9222096956031567,
                "precision": 0.895947426067908,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016272128021226318,
                "deletion_rate": 0.0016893992786368725
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.531578947368421,
                "recall": 0.455467869222097,
                "precision": 0.6382306477093207,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012290263973495778,
                "deletion_rate": 0.002778668376616437
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6319161327897496,
                "recall": 0.603448275862069,
                "precision": 0.66320293398533,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007184504576060076,
                "deletion_rate": 0.003083199451233821
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9936575052854122,
                "recall": 0.9903672486453944,
                "precision": 0.996969696969697,
                "correct_pairwise": 0,
                "hallucination_rate": 4.687824380704915e-05,
                "deletion_rate": 0.0003549352745390864
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6773238602723504,
                "recall": 0.6887417218543046,
                "precision": 0.6662783925451369,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00015623195690715066,
                "deletion_rate": 0.0018645944422179504
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ceb": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2816901408450704,
                "recall": 0.20408163265306123,
                "precision": 0.45454545454545453,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0011441647597254005
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9970501474926253,
                "recall": 1.0,
                "precision": 0.9941176470588236,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0030938466827088347,
                "deletion_rate": 0.00017188037126160193
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.625,
                "recall": 0.5325443786982249,
                "precision": 0.7563025210084033,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0023251654444643175,
                "deletion_rate": 0.0016097299230906814
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "cs": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9126712328767124,
                "recall": 0.9018612521150592,
                "precision": 0.9237435008665511,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015227653418608193,
                "deletion_rate": 0.001581333239624697
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.552317880794702,
                "recall": 0.4703891708967851,
                "precision": 0.6688051323175621,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0026995333838223438,
                "deletion_rate": 0.0036156646226760806
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6303711509190961,
                "recall": 0.5983551900422316,
                "precision": 0.6660069272637308,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0019024221574328332,
                "deletion_rate": 0.005664213071281632
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9298378189850607,
                "recall": 0.8761091028590207,
                "precision": 0.9905870696061432,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00040189940712206446,
                "deletion_rate": 0.0010225541877409488
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6427396949594603,
                "recall": 0.6211506849315068,
                "precision": 0.6658834586466166,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0013969161433012706,
                "deletion_rate": 0.0025392784860308387
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9590954439640839,
                "recall": 0.9285254346426272,
                "precision": 0.9917469050894085,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00044928675727282937,
                "deletion_rate": 0.0014483586254189895
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5975130890052356,
                "recall": 0.587894397939472,
                "precision": 0.6074517631403858,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001381324253751689,
                "deletion_rate": 0.0037077651021755857
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "cy": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4629629629629629,
                "recall": 0.3333333333333333,
                "precision": 0.7575757575757576,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0018779675430515201,
                "deletion_rate": 0.004092551909857558
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.20770355923939546,
                "recall": 0.1290909090909091,
                "precision": 0.5311720698254364,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006083494567643994,
                "deletion_rate": 0.0020650394403929156
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9870588235294118,
                "recall": 0.9789964994165694,
                "precision": 0.9952550415183867,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00041711138100671057,
                "deletion_rate": 0.0001472157815317802
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4996282527881041,
                "recall": 0.3920653442240373,
                "precision": 0.6885245901639344,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004433747149733975,
                "deletion_rate": 0.000709399543957436
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "da": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9317803660565723,
                "recall": 0.9406494960806271,
                "precision": 0.9230769230769231,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001009532030695626,
                "deletion_rate": 0.0013021500106074019
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5994415141172821,
                "recall": 0.5408734602463606,
                "precision": 0.6722338204592901,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007971575638864848,
                "deletion_rate": 0.001396923731001078
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6535724452035296,
                "recall": 0.6379904412581971,
                "precision": 0.6699346405228758,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005736955126292185,
                "deletion_rate": 0.0012923374498929954
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9518935516888434,
                "recall": 0.9153543307086615,
                "precision": 0.9914712153518124,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004268783583905937,
                "deletion_rate": 0.0031828649529123216
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6314699792960664,
                "recall": 0.6003937007874016,
                "precision": 0.665938864628821,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0001554665941155894,
                "deletion_rate": 0.0003886664852889735
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "de": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8379290939786157,
                "recall": 0.8738262910798122,
                "precision": 0.8048648648648649,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008018334838086459,
                "deletion_rate": 0.002601223585268993
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6466398265716939,
                "recall": 0.6126760563380281,
                "precision": 0.6845901639344262,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004972422682098624,
                "deletion_rate": 0.002747917798001871
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7128469113697404,
                "recall": 0.7079350966881529,
                "precision": 0.7178273608293892,
                "correct_pairwise": 0,
                "hallucination_rate": 0.003505669003388383,
                "deletion_rate": 0.002691706377643473
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.967251461988304,
                "recall": 0.9408418657565415,
                "precision": 0.9951865222623345,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002651681267911597,
                "deletion_rate": 0.001203455344667571
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7671541057367829,
                "recall": 0.7758816837315131,
                "precision": 0.7586206896551724,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005862216964837167,
                "deletion_rate": 0.004250107299506946
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9732065687121868,
                "recall": 0.955316742081448,
                "precision": 0.991779213153259,
                "correct_pairwise": 0,
                "hallucination_rate": 2.6929015116153818e-05,
                "deletion_rate": 0.001099601450576281
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7529473408435945,
                "recall": 0.8127828054298643,
                "precision": 0.7013177159590044,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00037564707499198317,
                "deletion_rate": 0.006596729121810436
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7834726424082814,
                "f1_success": 0.7834726424082814,
                "recall": 0.6617850577993488,
                "recall_success": 0.6617850577993488,
                "precision": 0.9660756573438994,
                "precision_success": 0.9660756573438994,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.00022528944962314188,
                "hallucination_rate_success": 0.00022528944962314188,
                "deletion_rate": 0.0019204568514467394,
                "deletion_rate_success": 0.0019204568514467394
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5920407383180792,
                "f1_success": 0.5920407383180792,
                "recall": 0.5196850573108305,
                "recall_success": 0.5196850573108305,
                "precision": 0.6972586325163447,
                "precision_success": 0.6972586325163447,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0004436358399903133,
                "hallucination_rate_success": 0.0004436358399903133,
                "deletion_rate": 0.0029532818335113544,
                "deletion_rate_success": 0.0029532818335113544
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.833600082879754,
                "f1_success": 0.833600082879754,
                "recall": 0.742347966632166,
                "recall_success": 0.742347966632166,
                "precision": 0.9533076419682033,
                "precision_success": 0.9533076419682033,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0009080290841756802,
                "hallucination_rate_success": 0.0009080290841756802,
                "deletion_rate": 0.0055146294529662505,
                "deletion_rate_success": 0.0055146294529662505
            }
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7419815878097253,
                "f1_success": 0.7419815878097253,
                "recall": 0.717094791861486,
                "recall_success": 0.717094791861486,
                "precision": 0.769598227029852,
                "precision_success": 0.769598227029852,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0006545361189937276,
                "hallucination_rate_success": 0.0006545361189937276,
                "deletion_rate": 0.0030738792959210236,
                "deletion_rate_success": 0.0030738792959210236
            }
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "el": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9425666391865897,
                "recall": 0.9575656058068118,
                "precision": 0.928030303030303,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001266308518802763,
                "deletion_rate": 0.000546815042210284
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5085574572127141,
                "recall": 0.4064768285873814,
                "precision": 0.6791044776119403,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016807221173144038,
                "deletion_rate": 0.001235825086260591
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5612928655892787,
                "recall": 0.4746666666666667,
                "precision": 0.686595949855352,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0011139088131945692,
                "deletion_rate": 0.0026564939043532292
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9468354430379746,
                "recall": 0.9121951219512195,
                "precision": 0.9842105263157894,
                "correct_pairwise": 0,
                "hallucination_rate": 3.216261417728033e-05,
                "deletion_rate": 0.0006271709764569664
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6869220607661823,
                "recall": 0.6341463414634146,
                "precision": 0.7492795389048992,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000638433709299851,
                "deletion_rate": 0.0017843403670175324
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "en": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9277652370203161,
                "recall": 0.9220415030846887,
                "precision": 0.9335604770017035,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007457804527018187,
                "deletion_rate": 0.0030747088839460945
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7999999999999999,
                "recall": 0.7986539540100953,
                "precision": 0.8013505908835116,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000906311717122528,
                "deletion_rate": 0.0023131239347455564
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6680829652820485,
                "recall": 0.6638888888888889,
                "precision": 0.6723303702036683,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00046279458113712344,
                "deletion_rate": 0.002509900538575786
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9475357710651828,
                "recall": 0.9066937119675457,
                "precision": 0.9922308546059934,
                "correct_pairwise": 0,
                "hallucination_rate": 8.934243964421855e-05,
                "deletion_rate": 0.0010125476493011436
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7103882476390347,
                "recall": 0.6866125760649088,
                "precision": 0.7358695652173913,
                "correct_pairwise": 0,
                "hallucination_rate": 3.0558922696111886e-05,
                "deletion_rate": 0.0010288170641024334
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9819457641985235,
                "recall": 0.968704932218056,
                "precision": 0.9955535793686082,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00010039082146797483,
                "deletion_rate": 0.0007479116199364124
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7659718005801796,
                "recall": 0.8187193539082781,
                "precision": 0.7196095829636202,
                "correct_pairwise": 0,
                "hallucination_rate": 6.788419367977586e-05,
                "deletion_rate": 0.0008331241951608856
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8922367357788888,
                "f1_success": 0.8922367357788888,
                "recall": 0.8234349791355353,
                "recall_success": 0.8234349791355353,
                "precision": 0.9778770916409213,
                "precision_success": 0.9778770916409213,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.00034346403169817753,
                "hallucination_rate_success": 0.00034346403169817753,
                "deletion_rate": 0.0023349062738609334,
                "deletion_rate_success": 0.0023349062738609334
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6920991032358444,
                "f1_success": 0.6920991032358444,
                "recall": 0.6781120228241735,
                "recall_success": 0.6781120228241735,
                "precision": 0.7186293521688591,
                "precision_success": 0.7186293521688591,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 9.704703416968173e-05,
                "hallucination_rate_success": 9.704703416968173e-05,
                "deletion_rate": 0.0015335851160265357,
                "deletion_rate_success": 0.0015335851160265357
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "en-de": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8215767634854771,
                "recall": 0.9183673469387755,
                "precision": 0.7432432432432432,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007750544784669647,
                "deletion_rate": 0.011378698357783119
            }
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5625,
                "recall": 0.601113172541744,
                "precision": 0.5285481239804242,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002909209393255289,
                "deletion_rate": 0.0010473153815719041
            }
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.899216487051897,
                "f1_success": 0.899216487051897,
                "recall": 0.9635731350663478,
                "recall_success": 0.9635731350663478,
                "precision": 0.879775429531632,
                "precision_success": 0.879775429531632,
                "correct_pairwise": 0.6133056133056133,
                "correct_pairwise_success": 0.6133056133056133,
                "hallucination_rate": 0.0006370849056134787,
                "hallucination_rate_success": 0.0006370849056134787,
                "deletion_rate": 0.009718267983594507,
                "deletion_rate_success": 0.009718267983594507
            }
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6767763917877446,
                "f1_success": 0.6767763917877446,
                "recall": 0.8175586437285662,
                "recall_success": 0.8175586437285662,
                "precision": 0.6345990341126608,
                "precision_success": 0.6345990341126608,
                "correct_pairwise": 0.11850311850311851,
                "correct_pairwise_success": 0.11850311850311851,
                "hallucination_rate": 0.0010736983348593233,
                "hallucination_rate_success": 0.0010736983348593233,
                "deletion_rate": 0.005756466286959291,
                "deletion_rate_success": 0.005756466286959291
            }
        }
    },
    "eo": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9160261884429263,
                "recall": 0.9024116657319126,
                "precision": 0.9300578034682081,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001938438321234356,
                "deletion_rate": 0.0005073764733432207
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6732612055641423,
                "recall": 0.6107683679192373,
                "precision": 0.75,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0013867551289546314,
                "deletion_rate": 0.001332372574877979
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5847194812517621,
                "recall": 0.5418916565058353,
                "precision": 0.6348979591836734,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000718930590746265,
                "deletion_rate": 0.0020344737203409928
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "es": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9361939258846474,
                "recall": 0.9432902863559798,
                "precision": 0.9292035398230089,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007130080182129767,
                "deletion_rate": 0.001225873434822311
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6127272727272728,
                "recall": 0.5676586187535093,
                "precision": 0.6655694535878868,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004050743600789574,
                "deletion_rate": 0.001041619783060176
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6390217969165337,
                "recall": 0.602539823994653,
                "precision": 0.6802062374245473,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005896122948201858,
                "deletion_rate": 0.0015477322739029878
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9847649918962722,
                "recall": 0.9812661498708011,
                "precision": 0.9882888744307091,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00014361058553625988,
                "deletion_rate": 0.0005600812835914135
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6862113402061855,
                "recall": 0.687984496124031,
                "precision": 0.6844473007712082,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00015439530344191245,
                "deletion_rate": 0.000694778865488606
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9832566697332107,
                "recall": 0.9691693870148712,
                "precision": 0.9977595220313666,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00024175416824478416,
                "deletion_rate": 0.0004861944939145104
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6689213243147027,
                "recall": 0.681537903518317,
                "precision": 0.6567633694512408,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00020887900683529067,
                "deletion_rate": 0.0008877357790499853
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7038474094376762,
                "f1_success": 0.7038474094376762,
                "recall": 0.572661175247794,
                "recall_success": 0.572661175247794,
                "precision": 0.947680383315367,
                "precision_success": 0.947680383315367,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0032343800086468946,
                "hallucination_rate_success": 0.0032343800086468946,
                "deletion_rate": 0.004975602300297705,
                "deletion_rate_success": 0.004975602300297705
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5050869280095259,
                "f1_success": 0.5050869280095259,
                "recall": 0.4237323792635769,
                "recall_success": 0.4237323792635769,
                "precision": 0.6682079889661346,
                "precision_success": 0.6682079889661346,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0025679865068117627,
                "hallucination_rate_success": 0.0025679865068117627,
                "deletion_rate": 0.0035159004128685312,
                "deletion_rate_success": 0.0035159004128685312
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6648358514904357,
                "f1_success": 0.6648358514904357,
                "recall": 0.5125253578959488,
                "recall_success": 0.5125253578959488,
                "precision": 0.9759027355403542,
                "precision_success": 0.9759027355403542,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0003445138441666999,
                "hallucination_rate_success": 0.0003445138441666999,
                "deletion_rate": 0.0026756747255556115,
                "deletion_rate_success": 0.0026756747255556115
            }
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5587316066381027,
                "f1_success": 0.5587316066381027,
                "recall": 0.4307246018227942,
                "recall_success": 0.4307246018227942,
                "precision": 0.8509224060340708,
                "precision_success": 0.8509224060340708,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0001512091733658365,
                "hallucination_rate_success": 0.0001512091733658365,
                "deletion_rate": 0.0011083481325874674,
                "deletion_rate_success": 0.0011083481325874674
            }
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "es-en": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9283842794759825,
                "recall": 0.8858333333333334,
                "precision": 0.9752293577981651,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004409064917085503,
                "deletion_rate": 0.019306588015770308
            }
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.47916666666666674,
                "recall": 0.44083333333333335,
                "precision": 0.5248015873015873,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008762459121563473,
                "deletion_rate": 0.0022062620288222316
            }
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "et": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8901767603593163,
                "recall": 0.862436833239753,
                "precision": 0.9197604790419162,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00196043047444058,
                "deletion_rate": 0.0017307566113262025
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4031238378579397,
                "recall": 0.3043234138124649,
                "precision": 0.5969162995594713,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00033169470479171273,
                "deletion_rate": 0.001871098334722482
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5315292315547613,
                "recall": 0.46266666666666667,
                "precision": 0.6244751049790042,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00045954936726225177,
                "deletion_rate": 0.001642031619740046
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9408823004107875,
                "recall": 0.9107883817427386,
                "precision": 0.9730328777244182,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003315393727146315,
                "deletion_rate": 0.000756424782407169
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4788445890968267,
                "recall": 0.406984785615491,
                "precision": 0.5815217391304348,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003968621433201487,
                "deletion_rate": 0.0011740505073221065
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9700226244343891,
                "recall": 0.9449035812672176,
                "precision": 0.9965136548518303,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00020309569696393538,
                "deletion_rate": 0.0018365036427589903
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4982720703738612,
                "recall": 0.4369146005509642,
                "precision": 0.5796783625730995,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003808511580532306,
                "deletion_rate": 0.0008502723528630265
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9177388767782068,
                "f1_success": 0.9177388767782068,
                "recall": 0.892944203263104,
                "recall_success": 0.892944203263104,
                "precision": 0.9658964735319413,
                "precision_success": 0.9658964735319413,
                "correct_pairwise": 0.5467980295566502,
                "correct_pairwise_success": 0.5467980295566502,
                "hallucination_rate": 0.0010983809387897269,
                "hallucination_rate_success": 0.0010983809387897269,
                "deletion_rate": 0.003637372325083711,
                "deletion_rate_success": 0.003637372325083711
            }
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5669393084451254,
                "f1_success": 0.5669393084451254,
                "recall": 0.5748643633755122,
                "recall_success": 0.5748643633755122,
                "precision": 0.6291463544665514,
                "precision_success": 0.6291463544665514,
                "correct_pairwise": 0.054187192118226604,
                "correct_pairwise_success": 0.054187192118226604,
                "hallucination_rate": 0.0007806303170134423,
                "hallucination_rate_success": 0.0007806303170134423,
                "deletion_rate": 0.002662472479524569,
                "deletion_rate_success": 0.002662472479524569
            }
        }
    },
    "eu": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.845185835528241,
                "recall": 0.8107804604154969,
                "precision": 0.882640586797066,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007596859964547987,
                "deletion_rate": 0.00090119613304932
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.30510846745976206,
                "recall": 0.24480628860190903,
                "precision": 0.40482822655524603,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0024132799790283657,
                "deletion_rate": 0.0016576843306424875
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.45005813338970513,
                "recall": 0.39779521674140506,
                "precision": 0.5181309321002677,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006467987920474973,
                "deletion_rate": 0.002865987750969083
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9733671528218135,
                "recall": 0.9481161210623842,
                "precision": 1.0,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003349914355963164,
                "deletion_rate": 0.005284015852047556
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.44532090354965936,
                "recall": 0.3835701050030883,
                "precision": 0.5307692307692308,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00015585630049094734,
                "deletion_rate": 0.0009221497779047718
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "fa": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6041131105398457,
                "recall": 0.5233853006681515,
                "precision": 0.7142857142857143,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0024784493399030343,
                "deletion_rate": 0.013399425315730748
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5576255131038838,
                "recall": 0.49192200557103066,
                "precision": 0.6435860058309038,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002079905628162543,
                "deletion_rate": 0.0013141692277444923
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6260381465146916,
                "recall": 0.6072222222222222,
                "precision": 0.6460574535997162,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020284655373087983,
                "deletion_rate": 0.004221129551481249
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9973231357552582,
                "recall": 0.9961802902979373,
                "precision": 0.998468606431853,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008964311390000798,
                "deletion_rate": 0.005857866848911413
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8969877277798438,
                "recall": 0.9213139801375095,
                "precision": 0.8739130434782608,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005882459411030064,
                "deletion_rate": 0.0005429962533258521
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "fi": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9392510402219142,
                "recall": 0.9458100558659218,
                "precision": 0.9327823691460055,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001235503889029287,
                "deletion_rate": 0.003903069103978884
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5522292993630573,
                "recall": 0.48435754189944136,
                "precision": 0.6422222222222222,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004552102199537042,
                "deletion_rate": 0.001840211527472421
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5594363117293324,
                "recall": 0.5116666666666667,
                "precision": 0.6170440841484658,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003240961431208568,
                "deletion_rate": 0.001831143208632841
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9585185185185185,
                "recall": 0.9249463902787706,
                "precision": 0.994619523443505,
                "correct_pairwise": 0,
                "hallucination_rate": 6.608773808107643e-05,
                "deletion_rate": 0.0024584638566160434
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6340014847809948,
                "recall": 0.6104360257326662,
                "precision": 0.6594594594594595,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00011475088931939223,
                "deletion_rate": 0.0013905107764585175
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9672977624784854,
                "recall": 0.9387527839643652,
                "precision": 0.9976331360946745,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00017692093242692629,
                "deletion_rate": 0.007934635757328815
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6542688081149619,
                "recall": 0.6464365256124721,
                "precision": 0.6622932116371933,
                "correct_pairwise": 0,
                "hallucination_rate": 7.644550254727336e-05,
                "deletion_rate": 0.0040516116350054875
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "fr": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.913826544749238,
                "recall": 0.9295377677564826,
                "precision": 0.8986376021798365,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001064520168956998,
                "deletion_rate": 0.0030797080823836143
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6445182724252492,
                "recall": 0.6014656144306652,
                "precision": 0.6942094990240729,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006088957324605828,
                "deletion_rate": 0.0012821938981621888
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6392740969012155,
                "recall": 0.6223333333333333,
                "precision": 0.6571629707849349,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00045086540208111683,
                "deletion_rate": 0.003201468718374549
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9906542056074765,
                "recall": 0.9919786096256684,
                "precision": 0.9893333333333333,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00020143015409406788,
                "deletion_rate": 0.0013898680632490684
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7225806451612905,
                "recall": 0.7486631016042781,
                "precision": 0.6982543640897756,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0001654978381844887,
                "deletion_rate": 0.00028962121682285524
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9789972899728997,
                "recall": 0.9678499665103818,
                "precision": 0.9904043865661412,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00013832644086067666,
                "deletion_rate": 0.00044359858620837683
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7324777887462982,
                "recall": 0.7454789015405224,
                "precision": 0.7199223803363519,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00031709637290533454,
                "deletion_rate": 0.0012439934629363124
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8553410784360195,
                "f1_success": 0.8553410784360195,
                "recall": 0.7694855829254675,
                "recall_success": 0.7694855829254675,
                "precision": 0.970478717878179,
                "precision_success": 0.970478717878179,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.00033991571476978106,
                "hallucination_rate_success": 0.00033991571476978106,
                "deletion_rate": 0.001339102530848083,
                "deletion_rate_success": 0.001339102530848083
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6003577768746724,
                "f1_success": 0.6003577768746724,
                "recall": 0.5640650692160706,
                "recall_success": 0.5640650692160706,
                "precision": 0.6648582717345891,
                "precision_success": 0.6648582717345891,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.000776263637572764,
                "hallucination_rate_success": 0.000776263637572764,
                "deletion_rate": 0.00158901978103394,
                "deletion_rate_success": 0.00158901978103394
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.527317401532291,
                "f1_success": 0.527317401532291,
                "recall": 0.4571205144402872,
                "recall_success": 0.4571205144402872,
                "precision": 0.6582475385042649,
                "precision_success": 0.6582475385042649,
                "correct_pairwise": 0.004357298474945534,
                "correct_pairwise_success": 0.004357298474945534,
                "hallucination_rate": 4.474804666844771e-05,
                "hallucination_rate_success": 4.474804666844771e-05,
                "deletion_rate": 0.0022215015812996316,
                "deletion_rate_success": 0.0022215015812996316
            }
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4070258776069714,
                "f1_success": 0.4070258776069714,
                "recall": 0.3828537910548782,
                "recall_success": 0.3828537910548782,
                "precision": 0.4754422480932415,
                "precision_success": 0.4754422480932415,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0004020142784319656,
                "hallucination_rate_success": 0.0004020142784319656,
                "deletion_rate": 0.0027224235449210136,
                "deletion_rate_success": 0.0027224235449210136
            }
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "fy": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4239359460598399,
                "recall": 0.29994036970781157,
                "precision": 0.7227011494252874,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0011092507325240687,
                "deletion_rate": 0.007325240686479699
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2748299319727891,
                "recall": 0.1806797853309481,
                "precision": 0.5738636363636364,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002926019739715259,
                "deletion_rate": 0.002467464407371823
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ga": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7130919220055709,
                "recall": 0.5739910313901345,
                "precision": 0.9411764705882353,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00024294251979981537,
                "deletion_rate": 0.0013078405649223394
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.25895765472312704,
                "recall": 0.17825112107623317,
                "precision": 0.4732142857142857,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00016895441939431902,
                "deletion_rate": 0.004800778014497113
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.08888888888888888,
                "recall": 0.04878048780487805,
                "precision": 0.5,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.00041339396444811904
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9453681710213776,
                "recall": 0.9754901960784313,
                "precision": 0.9170506912442397,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000334467900918803,
                "deletion_rate": 0.0009443799555354438
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.41254125412541254,
                "recall": 0.3078817733990148,
                "precision": 0.625,
                "correct_pairwise": 0,
                "hallucination_rate": 0.023976240116439163,
                "deletion_rate": 0.0013178081114039574
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "gd": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.627906976744186,
                "recall": 0.5277777777777778,
                "precision": 0.7749244712990937,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007763831635765384,
                "deletion_rate": 0.0028097676396103295
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.17031630170316303,
                "recall": 0.10802469135802469,
                "precision": 0.40229885057471265,
                "correct_pairwise": 0,
                "hallucination_rate": 0.01584279076852769,
                "deletion_rate": 0.0011996343971361109
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6759847522236341,
                "recall": 0.5428571428571428,
                "precision": 0.8956228956228957,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004653868528214078,
                "deletion_rate": 0.0031607523754120614
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2971768202080238,
                "recall": 0.20449897750511248,
                "precision": 0.5434782608695652,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00020222446916076846,
                "deletion_rate": 0.0008695652173913044
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "gl": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9075208913649025,
                "recall": 0.9131165919282511,
                "precision": 0.9019933554817275,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002477147442606936,
                "deletion_rate": 0.0011746098202032888
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5104712041884817,
                "recall": 0.437219730941704,
                "precision": 0.6132075471698113,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0014266030995086145,
                "deletion_rate": 0.0013290575884311025
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6155502392344498,
                "recall": 0.5721592172559484,
                "precision": 0.6660626456122185,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007494580365438216,
                "deletion_rate": 0.0016636729637658717
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9459854014598541,
                "recall": 0.9,
                "precision": 0.9969230769230769,
                "correct_pairwise": 0,
                "hallucination_rate": 7.891725525786213e-05,
                "deletion_rate": 0.0006510673558773626
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.600297176820208,
                "recall": 0.5611111111111111,
                "precision": 0.645367412140575,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012493702770780856,
                "deletion_rate": 0.0011889168765743072
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "gu": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3299425033171163,
                "recall": 0.21449108683151236,
                "precision": 0.7145593869731801,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0014037613605687033,
                "deletion_rate": 0.0021776298029335013
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.18889374726716224,
                "recall": 0.1242093156986774,
                "precision": 0.39416058394160586,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0027160542423586374,
                "deletion_rate": 0.006022555059143065
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.20436074211086822,
                "recall": 0.2560033703131583,
                "precision": 0.17005597014925372,
                "correct_pairwise": 0,
                "hallucination_rate": 0.01252931271768297,
                "deletion_rate": 0.026919262203701284
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9313501144164761,
                "recall": 0.888646288209607,
                "precision": 0.9783653846153846,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005028133604692925,
                "deletion_rate": 0.0012211181611397103
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.34437751004016065,
                "recall": 0.37445414847161573,
                "precision": 0.3187732342007435,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002730253505313788,
                "deletion_rate": 0.002947142802464883
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ha": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8811225840614244,
                "recall": 0.924958310172318,
                "precision": 0.8412537917087968,
                "correct_pairwise": 0,
                "hallucination_rate": 0.016394449848958065,
                "deletion_rate": 0.0007987302237468639
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.09465791940018745,
                "recall": 0.05614230127848805,
                "precision": 0.30149253731343284,
                "correct_pairwise": 0,
                "hallucination_rate": 0.04642297758461523,
                "deletion_rate": 0.0009387285155642225
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.0,
                "recall": 0.0,
                "precision": 0.0,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.003134796238244514
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "he": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9163168205989366,
                "recall": 0.9114699331848553,
                "precision": 0.9212155317951604,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001414075489876152,
                "deletion_rate": 0.002159961462558078
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3682140047206923,
                "recall": 0.26057906458797325,
                "precision": 0.6273458445040214,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005300031468936846,
                "deletion_rate": 0.0008281299170213823
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.36192316984778933,
                "recall": 0.24966666666666668,
                "precision": 0.6575943810359964,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0011433670365992219,
                "deletion_rate": 0.005221902149587412
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.933933933933934,
                "recall": 0.8810198300283286,
                "precision": 0.9936102236421726,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000482809442736259,
                "deletion_rate": 7.62330699057251e-05
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.46460980036297644,
                "recall": 0.3626062322946176,
                "precision": 0.6464646464646465,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00018458942038921997,
                "deletion_rate": 0.0037708981593797797
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "hi": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5956072351421188,
                "recall": 0.5191441441441441,
                "precision": 0.6984848484848485,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012132650310056618,
                "deletion_rate": 0.003483702515928538
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2850609756097561,
                "recall": 0.21058558558558557,
                "precision": 0.4410377358490566,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009984087859973168,
                "deletion_rate": 0.0021840192193691307
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.38700206845933144,
                "recall": 0.32222222222222224,
                "precision": 0.4843828294638383,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017145778441936372,
                "deletion_rate": 0.0037503113243409756
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9980184940554822,
                "recall": 0.9973597359735974,
                "precision": 0.998678122934567,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00013555406249631647,
                "deletion_rate": 0.0017445218477786814
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6901899961225281,
                "recall": 0.5874587458745875,
                "precision": 0.8364661654135338,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008230929001806946,
                "deletion_rate": 0.0005144330626129342
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9732884399551066,
                "recall": 0.9559082892416225,
                "precision": 0.9913122999542753,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004920712492206063,
                "deletion_rate": 0.004341012116411924
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5619072032812099,
                "recall": 0.48324514991181655,
                "precision": 0.6711573790569504,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006350697203959251,
                "deletion_rate": 0.008771042554728705
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "hu": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9417288041977354,
                "recall": 0.9541130386121992,
                "precision": 0.9296619411123228,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0023814270840256087,
                "deletion_rate": 0.002182051793269976
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.49277357192016513,
                "recall": 0.40067151650811417,
                "precision": 0.6398570151921358,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007423043911944142,
                "deletion_rate": 0.0022269131735832425
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.560603204524034,
                "recall": 0.49588706091596263,
                "precision": 0.6447463506287036,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005105612359764821,
                "deletion_rate": 0.001400045027810209
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9813200498132005,
                "recall": 0.9752475247524752,
                "precision": 0.9874686716791979,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00020885547201336674,
                "deletion_rate": 0.001163623344074472
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5178571428571429,
                "recall": 0.5024752475247525,
                "precision": 0.5342105263157895,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00010706474357993912,
                "deletion_rate": 0.0012388920328535813
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "hy": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7308904294588997,
                "recall": 0.642246835443038,
                "precision": 0.8479214539377481,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0028232756790720977,
                "deletion_rate": 0.009476017016073566
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.47684809098294073,
                "recall": 0.3718131433095804,
                "precision": 0.6645909991508633,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0024743070130998045,
                "deletion_rate": 0.005581891872331186
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5163462715807519,
                "recall": 0.46860762306922993,
                "precision": 0.5749147920927062,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004745547874495827,
                "deletion_rate": 0.017543510976701766
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.920353982300885,
                "recall": 0.874766355140187,
                "precision": 0.970954356846473,
                "correct_pairwise": 0,
                "hallucination_rate": 0.003113385929451653,
                "deletion_rate": 0.015240920649409923
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.48088531187122735,
                "recall": 0.44672897196261685,
                "precision": 0.5206971677559913,
                "correct_pairwise": 0,
                "hallucination_rate": 0.011914098349713829,
                "deletion_rate": 0.02399506082197267
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "id": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9226425748164879,
                "recall": 0.9289368959636157,
                "precision": 0.9164329781267526,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017840069028240947,
                "deletion_rate": 0.0036146545089899957
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.49217638691322896,
                "recall": 0.39340534394542354,
                "precision": 0.6571699905033238,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006117255554468044,
                "deletion_rate": 0.0015660174219438191
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5597564070032988,
                "recall": 0.4903311847077128,
                "precision": 0.6520839491575525,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00042714006882208703,
                "deletion_rate": 0.001757669962345433
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9933184855233853,
                "recall": 0.9911111111111112,
                "precision": 0.9955357142857143,
                "correct_pairwise": 0,
                "hallucination_rate": 5.8395134851050695e-05,
                "deletion_rate": 0.0013597724258173234
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5977011494252873,
                "recall": 0.5488888888888889,
                "precision": 0.6560424966799469,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00026475134724274283,
                "deletion_rate": 0.0010504650229308829
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ig": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3934262948207171,
                "recall": 0.265993265993266,
                "precision": 0.7552581261950286,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016271459129385524,
                "deletion_rate": 0.0013529078377241897
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.10059171597633136,
                "recall": 0.05723905723905724,
                "precision": 0.4146341463414634,
                "correct_pairwise": 0,
                "hallucination_rate": 0.011475159430251652,
                "deletion_rate": 0.0012410738152518425
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.07476635514018691,
                "recall": 0.043010752688172046,
                "precision": 0.2857142857142857,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008718395815170009,
                "deletion_rate": 0.0007265329845975008
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "is": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9509831071725284,
                "recall": 0.9592178770949721,
                "precision": 0.942888522789676,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0029146643159780475,
                "deletion_rate": 0.0009525976057098985
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.21837549933422104,
                "recall": 0.13743016759776536,
                "precision": 0.531317494600432,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009750044318383265,
                "deletion_rate": 0.0022454647521125094
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.39283986453797776,
                "recall": 0.28692579505300353,
                "precision": 0.6226993865030674,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004977834548050192,
                "deletion_rate": 0.002141408069727252
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.941378939442831,
                "recall": 0.9429002370178841,
                "precision": 0.9398625429553265,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001423227244887618,
                "deletion_rate": 0.0003965648669965499
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33088451366441374,
                "recall": 0.24262012497306615,
                "precision": 0.5200923787528868,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0029483977765983518,
                "deletion_rate": 0.0012614511650005187
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "it": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9069767441860465,
                "recall": 0.9400224215246636,
                "precision": 0.8761755485893417,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012556641371403614,
                "deletion_rate": 0.0023543702571381777
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.571944611679711,
                "recall": 0.5325112107623319,
                "precision": 0.6176853055916776,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00083307446838553,
                "deletion_rate": 0.0014825901556013669
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6495649733370755,
                "recall": 0.643532421310199,
                "precision": 0.6557116953762466,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008727159478090298,
                "deletion_rate": 0.0017675112604760776
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9812206572769954,
                "recall": 0.9653579676674365,
                "precision": 0.9976133651551312,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003371607320134115,
                "deletion_rate": 0.0006181280086912544
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7466666666666667,
                "recall": 0.7759815242494227,
                "precision": 0.7194860813704497,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00036408929769090736,
                "deletion_rate": 0.00021078854076842004
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8109522899348085,
                "f1_success": 0.8109522899348085,
                "recall": 0.7150370743338387,
                "recall_success": 0.7150370743338387,
                "precision": 0.9418977180525319,
                "precision_success": 0.9418977180525319,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0001023505184993108,
                "hallucination_rate_success": 0.0001023505184993108,
                "deletion_rate": 0.01739265249266973,
                "deletion_rate_success": 0.01739265249266973
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5416550831347876,
                "f1_success": 0.5416550831347876,
                "recall": 0.49815401743211746,
                "recall_success": 0.49815401743211746,
                "precision": 0.6205911086720479,
                "precision_success": 0.6205911086720479,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0002710895721389426,
                "hallucination_rate_success": 0.0002710895721389426,
                "deletion_rate": 0.016814819973430328,
                "deletion_rate_success": 0.016814819973430328
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7716122896902438,
                "f1_success": 0.7716122896902438,
                "recall": 0.7921993863932787,
                "recall_success": 0.7921993863932787,
                "precision": 0.8165279007608551,
                "precision_success": 0.8165279007608551,
                "correct_pairwise": 0.4090909090909091,
                "correct_pairwise_success": 0.4090909090909091,
                "hallucination_rate": 0.0005535752225670821,
                "hallucination_rate_success": 0.0005535752225670821,
                "deletion_rate": 0.0010131069344531485,
                "deletion_rate_success": 0.0010131069344531485
            }
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3560013937067671,
                "f1_success": 0.3560013937067671,
                "recall": 0.41209671602072134,
                "recall_success": 0.41209671602072134,
                "precision": 0.35954455851264,
                "precision_success": 0.35954455851264,
                "correct_pairwise": 0.014204545454545454,
                "correct_pairwise_success": 0.014204545454545454,
                "hallucination_rate": 0.0007064752561380622,
                "hallucination_rate_success": 0.0007064752561380622,
                "deletion_rate": 0.001696570921862626,
                "deletion_rate_success": 0.001696570921862626
            }
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ja": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.09034653465346536,
                "recall": 0.08147321428571429,
                "precision": 0.10138888888888889,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0023639264818864133,
                "deletion_rate": 0.004609656639678506
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.07129798903107862,
                "recall": 0.06529017857142858,
                "precision": 0.07852348993288591,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015159014973394381,
                "deletion_rate": 0.002660561811656973
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.03668763102725367,
                "recall": 0.04278253139237693,
                "precision": 0.032112770039202605,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009405619857865075,
                "deletion_rate": 0.005878512411165672
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9791231732776617,
                "recall": 0.9610655737704918,
                "precision": 0.997872340425532,
                "correct_pairwise": 0,
                "hallucination_rate": 9.1441111923921e-05,
                "deletion_rate": 0.000182882223847842
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6905027932960894,
                "recall": 0.6331967213114754,
                "precision": 0.7592137592137592,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 9.718172983479106e-05
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8711162255466053,
                "recall": 0.7852697095435685,
                "precision": 0.9780361757105943,
                "correct_pairwise": 0,
                "hallucination_rate": 7.736046106834796e-05,
                "deletion_rate": 0.007407264147294318
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.43542857142857144,
                "recall": 0.39522821576763484,
                "precision": 0.4847328244274809,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00042194983016519334,
                "deletion_rate": 0.0014346294225616575
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "jv": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9905607995558023,
                "recall": 0.9911111111111112,
                "precision": 0.9900110987791343,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00025409409104191284,
                "deletion_rate": 0.0002667987955940085
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.22628951747088186,
                "recall": 0.1511111111111111,
                "precision": 0.4503311258278146,
                "correct_pairwise": 0,
                "hallucination_rate": 9.187557422233889e-05,
                "deletion_rate": 0.0004987531172069825
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ka": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8918535339199545,
                "recall": 0.8727777777777778,
                "precision": 0.9117817759721416,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006004275772140767,
                "deletion_rate": 0.002350158446166209
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.06766553890768487,
                "recall": 0.03888888888888889,
                "precision": 0.26022304832713755,
                "correct_pairwise": 0,
                "hallucination_rate": 0.007268750804065354,
                "deletion_rate": 0.003296667953171234
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.38871071199486845,
                "recall": 0.303,
                "precision": 0.5420393559928444,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0034512069340421796,
                "deletion_rate": 0.014230414575070146
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "kk": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5639491398653702,
                "recall": 0.4323394495412844,
                "precision": 0.810752688172043,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001668335001668335,
                "deletion_rate": 0.0025233566900233566
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3194860813704497,
                "recall": 0.21387614678899083,
                "precision": 0.6311336717428088,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020760943202430123,
                "deletion_rate": 0.0012238029677221968
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5075721722669191,
                "recall": 0.40787221905305193,
                "precision": 0.6717820231756968,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005099047629491137,
                "deletion_rate": 0.0004084720950506341
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9850107066381157,
                "recall": 0.9766454352441614,
                "precision": 0.9935205183585313,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010894706848580335,
                "deletion_rate": 0.00010056652475612618
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.699439950217797,
                "recall": 0.5966029723991507,
                "precision": 0.8451127819548873,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004886050326318361,
                "deletion_rate": 0.0004013541339475797
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9899441340782122,
                "recall": 0.9833518312985572,
                "precision": 0.9966254218222722,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000479611796569365,
                "deletion_rate": 0.0093853445681613
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5452035886818496,
                "recall": 0.4384017758046615,
                "precision": 0.7208029197080292,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009395674115402125,
                "deletion_rate": 0.00453317060413216
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "km": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.09876543209876543,
                "recall": 0.07331042382588775,
                "precision": 0.15130023640661938,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003661784287616511,
                "deletion_rate": 0.01217265867731913
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.054858934169279,
                "recall": 0.04009163802978236,
                "precision": 0.08684863523573201,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0076979127491538174,
                "deletion_rate": 0.007991726212861977
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.05322128851540617,
                "recall": 0.03966597077244259,
                "precision": 0.08085106382978724,
                "correct_pairwise": 0,
                "hallucination_rate": 2.1938484489491466e-05,
                "deletion_rate": 0.006603483831336931
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8561132561132562,
                "recall": 0.7829566854990584,
                "precision": 0.9443498012492901,
                "correct_pairwise": 0,
                "hallucination_rate": 8.596530440314289e-06,
                "deletion_rate": 0.0013539535443495006
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.01423246357167062,
                "recall": 0.009887005649717515,
                "precision": 0.02539298669891173,
                "correct_pairwise": 0,
                "hallucination_rate": 0.007705961297025846,
                "deletion_rate": 0.0035282912680202607
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "kn": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2670509125840538,
                "recall": 0.1705521472392638,
                "precision": 0.6150442477876106,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020904209533959095,
                "deletion_rate": 0.0020494323072508913
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.16281407035175877,
                "recall": 0.09938650306748466,
                "precision": 0.45,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0023191703496258697,
                "deletion_rate": 0.005032162079376887
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.15612802498048403,
                "recall": 0.09737098344693282,
                "precision": 0.3937007874015748,
                "correct_pairwise": 0,
                "hallucination_rate": 0.008814842689838414,
                "deletion_rate": 0.01830248708562827
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ko": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7032339885859227,
                "recall": 0.6230337078651685,
                "precision": 0.8071324599708879,
                "correct_pairwise": 0,
                "hallucination_rate": 0.012691874805431165,
                "deletion_rate": 0.005843051797217366
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6806060606060607,
                "recall": 0.6308988764044944,
                "precision": 0.7388157894736842,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004466098254161592,
                "deletion_rate": 0.0018016646366220057
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7611667308432808,
                "recall": 0.8785555555555555,
                "precision": 0.6714504076086957,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015802867632070574,
                "deletion_rate": 0.0011684035110945798
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9987843423292,
                "recall": 0.9980563654033042,
                "precision": 0.9995133819951338,
                "correct_pairwise": 0,
                "hallucination_rate": 0.009483319436681664,
                "deletion_rate": 0.00047645662870284683
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9639684106614018,
                "recall": 0.9489795918367347,
                "precision": 0.9794383149448345,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00551226002661091,
                "deletion_rate": 0.0009408857631628968
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ku": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.41868365180467093,
                "recall": 0.2848064702484113,
                "precision": 0.7900641025641025,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000744464954057334,
                "deletion_rate": 0.002233394862172002
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.31154014918824047,
                "recall": 0.2050837666088966,
                "precision": 0.6478102189781022,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005150900356358208,
                "deletion_rate": 0.0012614449852305816
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33285489713621763,
                "recall": 0.27055555555555555,
                "precision": 0.4324276327472918,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012652651591683697,
                "deletion_rate": 0.0034060584782150266
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ky": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5830099180681327,
                "recall": 0.4470899470899471,
                "precision": 0.8376703841387856,
                "correct_pairwise": 0,
                "hallucination_rate": 0.02196736865988738,
                "deletion_rate": 0.003114622223138962
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33447098976109213,
                "recall": 0.22685185185185186,
                "precision": 0.6363636363636364,
                "correct_pairwise": 0,
                "hallucination_rate": 0.008431813713711527,
                "deletion_rate": 0.002337316236702418
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4110091743119266,
                "recall": 0.3035230352303523,
                "precision": 0.6363636363636364,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0014529972291680746
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "la": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33333333333333337,
                "recall": 0.2,
                "precision": 1.0,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9001390820584144,
                "recall": 0.8560846560846561,
                "precision": 0.9489736070381232,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00023049441051054513,
                "deletion_rate": 0.0006569090699550536
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.566246541653858,
                "recall": 0.4873015873015873,
                "precision": 0.6757153338224505,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00014185906302088876,
                "deletion_rate": 0.0010521213840715916
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "lt": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.827543424317618,
                "recall": 0.7477578475336323,
                "precision": 0.9263888888888889,
                "correct_pairwise": 0,
                "hallucination_rate": 0.10835316695605876,
                "deletion_rate": 0.0011324038350743215
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3692857142857142,
                "recall": 0.2897982062780269,
                "precision": 0.5088582677165354,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006795412178480583,
                "deletion_rate": 0.00099176285848095
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5218420888639621,
                "recall": 0.46553257727373804,
                "precision": 0.5936480930100666,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00044458840640461357,
                "deletion_rate": 0.0020400256591023127
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9429787234042553,
                "recall": 0.9008130081300812,
                "precision": 0.9892857142857143,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008429291788966659,
                "deletion_rate": 0.002634153684052081
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.37989949748743723,
                "recall": 0.3073170731707317,
                "precision": 0.49736842105263157,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002492483604131292,
                "deletion_rate": 0.0014799121399529543
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9493302271403611,
                "recall": 0.9055555555555556,
                "precision": 0.9975520195838433,
                "correct_pairwise": 0,
                "hallucination_rate": 9.32625574147619e-05,
                "deletion_rate": 0.0001942969946140873
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4682634730538922,
                "recall": 0.43444444444444447,
                "precision": 0.5077922077922078,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00198708791866506,
                "deletion_rate": 0.0014843307344245026
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "lv": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8313554028732043,
                "recall": 0.7498591549295774,
                "precision": 0.9327259985984583,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00035163198610019443,
                "deletion_rate": 0.001973275969056385
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.384257602862254,
                "recall": 0.30253521126760563,
                "precision": 0.5264705882352941,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00013683634373289546,
                "deletion_rate": 0.001971298576902025
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.46636252650517257,
                "recall": 0.4032222222222222,
                "precision": 0.5529483467926253,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00044371648160219994,
                "deletion_rate": 0.0018310152342658683
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9696684693157771,
                "recall": 0.9502304147465438,
                "precision": 0.9899183869419107,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006367472903381732,
                "deletion_rate": 0.0002788674264254773
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.46053702196908053,
                "recall": 0.3914246196403873,
                "precision": 0.5592885375494071,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006055625243306371,
                "deletion_rate": 0.0014225913269989572
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.987750556792873,
                "recall": 0.9774104683195592,
                "precision": 0.9983117613956106,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00014846830201751927,
                "deletion_rate": 0.0008413203780992758
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.49305769824128354,
                "recall": 0.4402203856749311,
                "precision": 0.5603085553997195,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00021622538316409812,
                "deletion_rate": 0.0014330231276365717
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "mg": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8565284178187405,
                "recall": 0.7840269966254219,
                "precision": 0.943805010155721,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00016489110018209712,
                "deletion_rate": 0.0007814404312977646
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.0776965265082267,
                "recall": 0.047806524184476944,
                "precision": 0.2073170731707317,
                "correct_pairwise": 0,
                "hallucination_rate": 4.108647582621168e-05,
                "deletion_rate": 0.0003249566724436742
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.08372093023255814,
                "recall": 0.046632124352331605,
                "precision": 0.4090909090909091,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0003975465697410268
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "mk": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9409844982322546,
                "recall": 0.9611111111111111,
                "precision": 0.921683537559936,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002086478274665154,
                "deletion_rate": 0.0012403488360912666
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4242204496011603,
                "recall": 0.325,
                "precision": 0.6106471816283925,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010546827915946804,
                "deletion_rate": 0.00019084736228856122
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5310443102395331,
                "recall": 0.434971098265896,
                "precision": 0.6815885734192649,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0026350785295228443,
                "deletion_rate": 0.00248991547327462
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ml": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8089228059876725,
                "recall": 0.7689732142857143,
                "precision": 0.853250773993808,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001774776529662576,
                "deletion_rate": 0.005097071618726056
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.23833757421543683,
                "recall": 0.15680803571428573,
                "precision": 0.49646643109540634,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015102203282680465,
                "deletion_rate": 0.005947224238450912
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2517233711363131,
                "recall": 0.20793534166054373,
                "precision": 0.3188732394366197,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004813460600472089,
                "deletion_rate": 0.04214270201759476
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "mn": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4934911242603551,
                "recall": 0.3316542948038176,
                "precision": 0.9637904468412943,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004045275973394531,
                "deletion_rate": 0.0017244285399406175
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.34857382550335575,
                "recall": 0.2203659506762132,
                "precision": 0.8335005015045135,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0025090271877655054,
                "deletion_rate": 0.0013939039932030586
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.454095826893354,
                "recall": 0.3264807200800089,
                "precision": 0.7454960669880741,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002788284650925583,
                "deletion_rate": 0.0009258865743411027
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "mr": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8811315076737888,
                "recall": 0.8192501398992725,
                "precision": 0.953125,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0029050451981766207,
                "deletion_rate": 0.0014834273352391254
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.22383325781603988,
                "recall": 0.13822048125349748,
                "precision": 0.5880952380952381,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0038420818961101056,
                "deletion_rate": 0.0022369454595129947
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.1564255617977528,
                "recall": 0.099,
                "precision": 0.3724916387959866,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004398239646554448,
                "deletion_rate": 0.0011607016560489345
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9,
                "recall": 0.8571428571428571,
                "precision": 0.9473684210526315,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006246450880181715,
                "deletion_rate": 0.0017035775127768314
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.19999999999999998,
                "recall": 0.11904761904761904,
                "precision": 0.625,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ms": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9099360836722835,
                "recall": 0.8958810068649885,
                "precision": 0.9244391971664699,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0020508566359038172,
                "deletion_rate": 0.002154551634348392
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4473211075152823,
                "recall": 0.35583524027459956,
                "precision": 0.6021297192642788,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0028808370097152913,
                "deletion_rate": 0.0016031436079168777
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5786644802769427,
                "recall": 0.5251322751322751,
                "precision": 0.6443497666869548,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006580159503066354,
                "deletion_rate": 0.001883805663449282
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "mt": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7880347378578321,
                "recall": 0.6897522522522522,
                "precision": 0.918979744936234,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000466743625921017,
                "deletion_rate": 0.002761269542662505
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.24327678940835748,
                "recall": 0.16554054054054054,
                "precision": 0.45865834633385333,
                "correct_pairwise": 0,
                "hallucination_rate": 0.010646307274976638,
                "deletion_rate": 0.011077607569698505
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3529411764705882,
                "recall": 0.2608695652173913,
                "precision": 0.5454545454545454,
                "correct_pairwise": 0,
                "hallucination_rate": 0.394643254056457,
                "deletion_rate": 0.00144476550344521
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9435215946843853,
                "recall": 0.9141630901287554,
                "precision": 0.9748283752860412,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00018942003030720484,
                "deletion_rate": 0.002273040363686458
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.23696682464454977,
                "recall": 0.1609442060085837,
                "precision": 0.4491017964071856,
                "correct_pairwise": 0,
                "hallucination_rate": 0.005528467073900197,
                "deletion_rate": 0.0010513150501187262
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "my": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.16268717118575474,
                "recall": 0.11254199328107503,
                "precision": 0.2934306569343066,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004758991093888096,
                "deletion_rate": 0.004917624130351032
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.09560229445506692,
                "recall": 0.06998880179171332,
                "precision": 0.15078407720144751,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00038298168651208135,
                "deletion_rate": 0.0074275236172040016
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.060217176702862786,
                "recall": 0.05423427428317404,
                "precision": 0.06768377253814147,
                "correct_pairwise": 0,
                "hallucination_rate": 0.010585394866350798,
                "deletion_rate": 0.06759549815223378
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ne": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3965591397849462,
                "recall": 0.2708578143360752,
                "precision": 0.7399678972712681,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0014392078599938594,
                "deletion_rate": 0.0050084433527786305
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4662921348314607,
                "recall": 0.34136310223266747,
                "precision": 0.7354430379746836,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016771488469601676,
                "deletion_rate": 0.002056503943296396
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4781936282090937,
                "recall": 0.41492216854535696,
                "precision": 0.5642335766423358,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006747187558453358,
                "deletion_rate": 0.0015632097907703818
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "nl": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9371489703129179,
                "recall": 0.9733333333333334,
                "precision": 0.9035585353274884,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016506653191847734,
                "deletion_rate": 0.0019089326820504182
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6601597160603372,
                "recall": 0.62,
                "precision": 0.7058823529411765,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010821251541737451,
                "deletion_rate": 0.002955481603872379
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7092548974550468,
                "recall": 0.6862701500833797,
                "precision": 0.7338326200665716,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000579727554163397,
                "deletion_rate": 0.0025800487545650282
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9595375722543351,
                "recall": 0.9291044776119403,
                "precision": 0.9920318725099602,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00016733601070950468,
                "deletion_rate": 0.0014755993671656323
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7419056429232191,
                "recall": 0.7481343283582089,
                "precision": 0.7357798165137615,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017362187635642091,
                "deletion_rate": 0.0007905996155515595
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "no": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9530864197530864,
                "recall": 0.9720201454952434,
                "precision": 0.9348762109795479,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0025087736606954096,
                "deletion_rate": 0.0008738425110287381
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6589122917321597,
                "recall": 0.5864577504196978,
                "precision": 0.7517934002869441,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016371198489720067,
                "deletion_rate": 0.0018436034335270347
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9647407407407408,
                "recall": 0.9329512893982808,
                "precision": 0.9987730061349693,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002800928663459085,
                "deletion_rate": 0.001985547208096551
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6690712353471596,
                "recall": 0.6378223495702006,
                "precision": 0.7035398230088495,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006113909781618785,
                "deletion_rate": 0.001706799814035244
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "pa": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.26672777268560954,
                "recall": 0.16562322140011382,
                "precision": 0.6847058823529412,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017854370439372767,
                "deletion_rate": 0.005226931635874347
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.20410022779043283,
                "recall": 0.1275626423690205,
                "precision": 0.510250569476082,
                "correct_pairwise": 0,
                "hallucination_rate": 0.003639973527465255,
                "deletion_rate": 0.011885065078314582
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3126934984520124,
                "recall": 0.2961876832844575,
                "precision": 0.33114754098360655,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0037746621835944936,
                "deletion_rate": 0.035462792615618854
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "pl": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9377410468319558,
                "recall": 0.9545709478407179,
                "precision": 0.9214943151055766,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0026223113181990574,
                "deletion_rate": 0.0013111556590995287
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6049185563717663,
                "recall": 0.5311273135165452,
                "precision": 0.7025222551928784,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017686354470592212,
                "deletion_rate": 0.0014870055988013833
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6575523175631108,
                "recall": 0.6103751530669042,
                "precision": 0.7126332206914479,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009519076059944907,
                "deletion_rate": 0.0021031822917105415
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9929506545820745,
                "recall": 0.9894631209232313,
                "precision": 0.9964628600303184,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003828855274375769,
                "deletion_rate": 0.0002552570182917179
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6704516129032259,
                "recall": 0.6517812343201205,
                "precision": 0.6902231668437833,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017102805699536231,
                "deletion_rate": 0.0011436845529137726
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9538106235565821,
                "recall": 0.9137168141592921,
                "precision": 0.9975845410628019,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003203531003061152,
                "deletion_rate": 0.00034704919199829144
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6293706293706295,
                "recall": 0.5973451327433629,
                "precision": 0.6650246305418719,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017605794404458917,
                "deletion_rate": 0.0008392399405234303
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ps": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.26078334159643035,
                "recall": 0.16274752475247525,
                "precision": 0.655860349127182,
                "correct_pairwise": 0,
                "hallucination_rate": 0.010667123992454125,
                "deletion_rate": 0.005213513977019379
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.2870999030067895,
                "recall": 0.18316831683168316,
                "precision": 0.6636771300448431,
                "correct_pairwise": 0,
                "hallucination_rate": 0.005817335660267597,
                "deletion_rate": 0.0014543339150668994
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5051903114186851,
                "recall": 0.44421906693711966,
                "precision": 0.5855614973262032,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005170023265104693,
                "deletion_rate": 0.0005875026437618969
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.963320058687906,
                "recall": 0.9368120668569099,
                "precision": 0.99137187230371,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003563777604260516,
                "deletion_rate": 0.0003723947384227281
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6375202405736756,
                "recall": 0.5617611088463106,
                "precision": 0.7368983957219252,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006896834845437005,
                "deletion_rate": 0.003694732952912681
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "pt": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9411441144114411,
                "recall": 0.9606962380685008,
                "precision": 0.9223719676549865,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001643960945206067,
                "deletion_rate": 0.0008577187540205566
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5812869132732359,
                "recall": 0.5249859629421674,
                "precision": 0.6511142061281338,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00022132217869552708,
                "deletion_rate": 0.000959062774347284
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6615715309290662,
                "recall": 0.6156239582175798,
                "precision": 0.7149309588333979,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005535417527765484,
                "deletion_rate": 0.0014631059544754582
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9348813730439172,
                "recall": 0.8819047619047619,
                "precision": 0.9946294307196563,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00022847540572809954,
                "deletion_rate": 0.0016361787119883256
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6274509803921569,
                "recall": 0.5942857142857143,
                "precision": 0.6645367412140575,
                "correct_pairwise": 0,
                "hallucination_rate": 6.0574396716867696e-05,
                "deletion_rate": 0.0008253261552673224
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8115233542617579,
                "f1_success": 0.8115233542617579,
                "recall": 0.7699378047243919,
                "recall_success": 0.7699378047243919,
                "precision": 0.8739924236670811,
                "precision_success": 0.8739924236670811,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.00038436827638679925,
                "hallucination_rate_success": 0.00038436827638679925,
                "deletion_rate": 0.003536775754674823,
                "deletion_rate_success": 0.003536775754674823
            }
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5207146248791963,
                "f1_success": 0.5207146248791963,
                "recall": 0.46318300330932755,
                "recall_success": 0.46318300330932755,
                "precision": 0.6073436679569005,
                "precision_success": 0.6073436679569005,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0001951654817221239,
                "hallucination_rate_success": 0.0001951654817221239,
                "deletion_rate": 0.002196155735392704,
                "deletion_rate_success": 0.002196155735392704
            }
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.498499591779185,
                "f1_success": 0.498499591779185,
                "recall": 0.41199150976902843,
                "recall_success": 0.41199150976902843,
                "precision": 0.7181267053421895,
                "precision_success": 0.7181267053421895,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.0012045126318469622,
                "hallucination_rate_success": 0.0012045126318469622,
                "deletion_rate": 0.00819693803445955,
                "deletion_rate_success": 0.00819693803445955
            }
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.45406734413633626,
                "f1_success": 0.45406734413633626,
                "recall": 0.3822220918576872,
                "recall_success": 0.3822220918576872,
                "precision": 0.6327317408227991,
                "precision_success": 0.6327317408227991,
                "correct_pairwise": 0.0,
                "correct_pairwise_success": 0.0,
                "hallucination_rate": 0.000278596215206653,
                "hallucination_rate_success": 0.000278596215206653,
                "deletion_rate": 0.004035948055438261,
                "deletion_rate_success": 0.004035948055438261
            }
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ro": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9491051454138704,
                "recall": 0.952300785634119,
                "precision": 0.9459308807134894,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0026216006390854777,
                "deletion_rate": 0.0018902528213148508
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5229327084030799,
                "recall": 0.4382716049382716,
                "precision": 0.6481327800829876,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0013013353341852585,
                "deletion_rate": 0.002157168481892681
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6351286939942803,
                "recall": 0.5925514174541412,
                "precision": 0.6842983694954423,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005783553021096257,
                "deletion_rate": 0.0018285500607647003
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9354838709677419,
                "recall": 0.9809725158562368,
                "precision": 0.8940269749518305,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00028504530184261426,
                "deletion_rate": 0.00043774814211544334
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3968565815324165,
                "recall": 0.3202959830866808,
                "precision": 0.5215146299483648,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008296314965922099,
                "deletion_rate": 0.0015542463480461653
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.97678369195923,
                "recall": 0.9583333333333334,
                "precision": 0.995958429561201,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00010135059046103258,
                "deletion_rate": 0.0003828800084083453
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5954198473282444,
                "recall": 0.585,
                "precision": 0.6062176165803109,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00019581719121356745,
                "deletion_rate": 0.0009022949006899676
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ru": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8926389292988071,
                "recall": 0.8735763097949886,
                "precision": 0.9125520523497918,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003185371397086677,
                "deletion_rate": 0.0010675298736182377
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6179275270184361,
                "recall": 0.5535307517084282,
                "precision": 0.6992805755395683,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007528377883559136,
                "deletion_rate": 0.0019860856829000367
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6522428083861531,
                "recall": 0.5946216246249584,
                "precision": 0.7222297206100688,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009510585044324562,
                "deletion_rate": 0.0016141818653211413
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8851828094932649,
                "recall": 0.8712121212121212,
                "precision": 0.8996088657105606,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006577340123653994,
                "deletion_rate": 0.004378629282318231
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.48475609756097565,
                "recall": 0.4015151515151515,
                "precision": 0.6115384615384616,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0011599331563943772,
                "deletion_rate": 0.0022215668927553327
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9700115340253749,
                "recall": 0.9438832772166106,
                "precision": 0.9976275207591934,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004363285275304734,
                "deletion_rate": 0.0009190749835216354
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6746126340882002,
                "recall": 0.6352413019079686,
                "precision": 0.7191867852604829,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005534087114164401,
                "deletion_rate": 0.0021850102571442202
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "si": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7692307692307692,
                "recall": 0.6978699551569507,
                "precision": 0.8568479008947006,
                "correct_pairwise": 0,
                "hallucination_rate": 0.04626104736410229,
                "deletion_rate": 0.005636341624181116
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3724188790560472,
                "recall": 0.2830717488789238,
                "precision": 0.5441810344827587,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0024724425672195322,
                "deletion_rate": 0.0018984826855435693
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.34515366430260047,
                "recall": 0.3146551724137931,
                "precision": 0.38219895287958117,
                "correct_pairwise": 0,
                "hallucination_rate": 0.010440641084654978,
                "deletion_rate": 0.033811775536678246
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "sk": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9434806939003918,
                "recall": 0.9455973079080202,
                "precision": 0.9413735343383585,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0018497866992370736,
                "deletion_rate": 0.0011948382985502628
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.48047010024196335,
                "recall": 0.38979248457655635,
                "precision": 0.6261261261261262,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006618924608610118,
                "deletion_rate": 0.0020316421368094945
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5716629851688231,
                "recall": 0.5033900188951873,
                "precision": 0.6613609813084113,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0013528689987811868,
                "deletion_rate": 0.0031311598970779945
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.906392694063927,
                "recall": 0.8322851153039832,
                "precision": 0.9949874686716792,
                "correct_pairwise": 0,
                "hallucination_rate": 1.3082669387861899e-05,
                "deletion_rate": 0.0006018027918416474
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6628830874006811,
                "recall": 0.6121593291404612,
                "precision": 0.7227722772277227,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010426831713609688,
                "deletion_rate": 0.0009758445065301375
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "sl": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9376544905245812,
                "recall": 0.9515050167224081,
                "precision": 0.924201407688143,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0025814183972157558,
                "deletion_rate": 0.002051305690644663
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5118577075098814,
                "recall": 0.4331103678929766,
                "precision": 0.6256038647342995,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0011702961935211437,
                "deletion_rate": 0.0019303854738493094
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5605846588466499,
                "recall": 0.5071111111111111,
                "precision": 0.626664835919264,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006794097420728625,
                "deletion_rate": 0.0014527216436192101
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9855326611135466,
                "recall": 0.9748482220294883,
                "precision": 0.9964539007092199,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00015672417969139584,
                "deletion_rate": 0.0014033937908729537
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5935604293047131,
                "recall": 0.5516045099739809,
                "precision": 0.6424242424242425,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004167001732595457,
                "deletion_rate": 0.0010088530510494265
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8302314071558937,
                "f1_success": 0.8302314071558937,
                "recall": 0.8714582460550201,
                "recall_success": 0.8714582460550201,
                "precision": 0.8318262962599492,
                "precision_success": 0.8318262962599492,
                "correct_pairwise": 0.4633431085043988,
                "correct_pairwise_success": 0.4633431085043988,
                "hallucination_rate": 0.004081883228045568,
                "hallucination_rate_success": 0.004081883228045568,
                "deletion_rate": 0.02186771025984602,
                "deletion_rate_success": 0.02186771025984602
            }
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6856436908636155,
                "f1_success": 0.6856436908636155,
                "recall": 0.6672000826234706,
                "recall_success": 0.6672000826234706,
                "precision": 0.7884698766938508,
                "precision_success": 0.7884698766938508,
                "correct_pairwise": 0.23936950146627567,
                "correct_pairwise_success": 0.23936950146627567,
                "hallucination_rate": 0.002608565983595842,
                "hallucination_rate_success": 0.002608565983595842,
                "deletion_rate": 0.01242321468172652,
                "deletion_rate_success": 0.01242321468172652
            }
        }
    },
    "sq": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9225589225589227,
                "recall": 0.9272419627749577,
                "precision": 0.9179229480737019,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001898166164989556,
                "deletion_rate": 0.001421639094280881
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.43111266131845133,
                "recall": 0.34856175972927245,
                "precision": 0.5648994515539305,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0003303737352880446,
                "deletion_rate": 0.0016188313029114187
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4933386624034106,
                "recall": 0.4114901655739527,
                "precision": 0.6158323632130385,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005662303042730582,
                "deletion_rate": 0.003081644351444936
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 1.0,
                "recall": 1.0,
                "precision": 1.0,
                "correct_pairwise": 1,
                "hallucination_rate": 0.0003750234389649353,
                "deletion_rate": 0.0
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8108108108108109,
                "recall": 0.8333333333333334,
                "precision": 0.7894736842105263,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0,
                "deletion_rate": 0.0007627765064836003
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "sr": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9462719298245614,
                "recall": 0.9631696428571429,
                "precision": 0.9299568965517241,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002617561218212991,
                "deletion_rate": 0.001164814742104781
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5430197522597926,
                "recall": 0.4525669642857143,
                "precision": 0.6786610878661088,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001979707993071022,
                "deletion_rate": 0.0019659600208969175
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5692594897324206,
                "recall": 0.5082222222222222,
                "precision": 0.6469589816124469,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001125712868832135,
                "deletion_rate": 0.0019724770642201837
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9648351648351648,
                "recall": 0.938034188034188,
                "precision": 0.9932126696832579,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002984451010236667,
                "deletion_rate": 0.009072731071119467
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6609257265877287,
                "recall": 0.655982905982906,
                "precision": 0.665943600867679,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008103603810222773,
                "deletion_rate": 0.001483112395455866
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9194587241462248,
                "f1_success": 0.9194587241462248,
                "recall": 0.9372395833333328,
                "recall_success": 0.9372395833333328,
                "precision": 0.923784722222222,
                "precision_success": 0.923784722222222,
                "correct_pairwise": 0.7135416666666666,
                "correct_pairwise_success": 0.7135416666666666,
                "hallucination_rate": 0.0013961414512797486,
                "hallucination_rate_success": 0.0013961414512797486,
                "deletion_rate": 0.008095481069393238,
                "deletion_rate_success": 0.008095481069393238
            }
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6690273268398274,
                "f1_success": 0.6690273268398274,
                "recall": 0.7321180555555559,
                "recall_success": 0.7321180555555559,
                "precision": 0.668721064814815,
                "precision_success": 0.668721064814815,
                "correct_pairwise": 0.19270833333333334,
                "correct_pairwise_success": 0.19270833333333334,
                "hallucination_rate": 0.0012995441584618547,
                "hallucination_rate_success": 0.0012995441584618547,
                "deletion_rate": 0.0041681823658253825,
                "deletion_rate_success": 0.0041681823658253825
            }
        }
    },
    "sv": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9426611796982167,
                "recall": 0.9592406476828588,
                "precision": 0.9266450916936354,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017606809078771696,
                "deletion_rate": 0.0006842456608811749
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6436090225563911,
                "recall": 0.5974316024567281,
                "precision": 0.6975228161668839,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010037662683058655,
                "deletion_rate": 0.0018102109625003217
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.632955223880597,
                "recall": 0.5892618941751889,
                "precision": 0.6836471498581377,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006583360868302744,
                "deletion_rate": 0.002386781212139417
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9551593733117234,
                "recall": 0.949516648764769,
                "precision": 0.9608695652173913,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006514586047744186,
                "deletion_rate": 0.001170417154340481
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.68561872909699,
                "recall": 0.6605800214822771,
                "precision": 0.712630359212051,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00032731746407973003,
                "deletion_rate": 0.001501145611124279
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ta": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.45253283302063796,
                "recall": 0.34067796610169493,
                "precision": 0.6737430167597765,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009050133762966057,
                "deletion_rate": 0.007787093116925739
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.17019360648356596,
                "recall": 0.10677966101694915,
                "precision": 0.4190687361419069,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0363762719248203,
                "deletion_rate": 0.02237342986650624
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.1461296601287618,
                "recall": 0.09648082245947015,
                "precision": 0.30104873534855026,
                "correct_pairwise": 0,
                "hallucination_rate": 0.006700052200749167,
                "deletion_rate": 0.010707845982932458
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9665071770334929,
                "recall": 0.9351851851851852,
                "precision": 1.0,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006355483369818516,
                "deletion_rate": 0.0
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3105590062111801,
                "recall": 0.23148148148148148,
                "precision": 0.4716981132075472,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00037227309954582683,
                "deletion_rate": 0.006849825031643214
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9695603156708005,
                "recall": 0.9513274336283186,
                "precision": 0.9885057471264368,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012920112029874632,
                "deletion_rate": 0.0064017071218991735
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.223717409587889,
                "recall": 0.14712389380530974,
                "precision": 0.4666666666666667,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0043814501016179695,
                "deletion_rate": 0.031769912283017045
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "te": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6588836191171106,
                "recall": 0.5121951219512195,
                "precision": 0.9233128834355828,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002751287342219248,
                "deletion_rate": 0.0014685925678062201
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.21361815754339122,
                "recall": 0.13613159387407828,
                "precision": 0.49586776859504134,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0019383403725694232,
                "deletion_rate": 0.0027136765215971925
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.33048433048433046,
                "recall": 0.26795464090718185,
                "precision": 0.43108108108108106,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00263705633462833,
                "deletion_rate": 0.005151141130336168
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "tg": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7607818802358053,
                "recall": 0.6837702175125489,
                "precision": 0.8573426573426574,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007485678714669567,
                "deletion_rate": 0.0020723510546927326
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.35893648449039883,
                "recall": 0.27105409927495816,
                "precision": 0.5311475409836065,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006968469724048599,
                "deletion_rate": 0.001877387725655446
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4471153846153846,
                "recall": 0.34191176470588236,
                "precision": 0.6458333333333334,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017853278511144775,
                "deletion_rate": 0.0012443194113828176
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "th": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6604379562043795,
                "recall": 0.6346801346801347,
                "precision": 0.6883749239196592,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0028094744121715076,
                "deletion_rate": 0.0025933609958506223
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6414777497900923,
                "recall": 0.6430976430976431,
                "precision": 0.6398659966499163,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0027600911268181555,
                "deletion_rate": 0.00026286582160172907
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5784341356180598,
                "recall": 0.5701111111111111,
                "precision": 0.5870037753117492,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001002232567594559,
                "deletion_rate": 0.0017208144085114128
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8142857142857143,
                "recall": 0.8233333333333334,
                "precision": 0.8054347826086956,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008094738420026983,
                "deletion_rate": 0.0017788437515614851
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8083427282976324,
                "recall": 0.7966666666666666,
                "precision": 0.8203661327231121,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001102701618966468,
                "deletion_rate": 0.0012029472206906923
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "tr": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9381557150745443,
                "recall": 0.9555680539932508,
                "precision": 0.9213665943600867,
                "correct_pairwise": 0,
                "hallucination_rate": 0.003591003591003591,
                "deletion_rate": 0.002041202041202041
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6344916344916345,
                "recall": 0.5545556805399325,
                "precision": 0.7413533834586467,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001003949749673056,
                "deletion_rate": 0.0017040726014187395
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6778625954198473,
                "recall": 0.6416184971098265,
                "precision": 0.7184466019417476,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00330476748963603,
                "deletion_rate": 0.00373853412318718
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9754851889683349,
                "recall": 0.9646464646464646,
                "precision": 0.9865702479338843,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0013219766060342374,
                "deletion_rate": 0.0006860891246506803
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6197827329902802,
                "recall": 0.5474747474747474,
                "precision": 0.7140974967061924,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009232484409295196,
                "deletion_rate": 0.0011497056056858168
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9426972795678178,
                "recall": 0.9021418020679468,
                "precision": 0.9870707070707071,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00033738665916918534,
                "deletion_rate": 0.0012764461938567513
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7359004278490858,
                "recall": 0.6986706056129985,
                "precision": 0.7773212818405916,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0008113742543152983,
                "deletion_rate": 0.004729647788499853
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "tr-de": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9896623018607857,
                "recall": 0.9917127071823204,
                "precision": 0.9876203576341128,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0004725835882221668,
                "deletion_rate": 0.001037058429709755
            }
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3391655450874832,
                "recall": 0.34806629834254144,
                "precision": 0.33070866141732286,
                "correct_pairwise": 0,
                "hallucination_rate": 0.055285946579607476,
                "deletion_rate": 0.0017268980121765217
            }
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "uk": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9113785557986872,
                "recall": 0.9302065884980458,
                "precision": 0.8932975871313673,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0027596172067462575,
                "deletion_rate": 0.003612374455182869
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5429833503227999,
                "recall": 0.44611948632049137,
                "precision": 0.6935763888888888,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00548099132280417,
                "deletion_rate": 0.006192646232598789
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.6170639899623588,
                "recall": 0.5466874166296132,
                "precision": 0.7082373271889401,
                "correct_pairwise": 0,
                "hallucination_rate": 0.004379665703827954,
                "deletion_rate": 0.004147887739079641
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9489334195216548,
                "recall": 0.9084158415841584,
                "precision": 0.993234100135318,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0006689430699494798,
                "deletion_rate": 0.001577507538089818
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5261606484893147,
                "recall": 0.44183168316831684,
                "precision": 0.6502732240437158,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010244417309960886,
                "deletion_rate": 0.0012727912415405947
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "ur": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.47563083304528175,
                "recall": 0.4044679600235156,
                "precision": 0.5771812080536913,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0007185284537267676,
                "deletion_rate": 0.0016765663920291244
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.43088655862726405,
                "recall": 0.3985890652557319,
                "precision": 0.46887966804979253,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005875632446548065,
                "deletion_rate": 0.0013056960992329036
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4872180451127819,
                "recall": 0.4160958904109589,
                "precision": 0.5876662636033857,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002606285504179655,
                "deletion_rate": 0.0016863331704097258
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9696356275303644,
                "recall": 0.9958419958419958,
                "precision": 0.9447731755424064,
                "correct_pairwise": 0,
                "hallucination_rate": 0.040715276009393654,
                "deletion_rate": 8.48824378236143e-05
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.838235294117647,
                "recall": 0.8295218295218295,
                "precision": 0.8471337579617835,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0403235057932775,
                "deletion_rate": 0.00048755305724446486
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "uz": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.674269819193324,
                "recall": 0.6870748299319728,
                "precision": 0.6619333697433096,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0012243266203588027,
                "deletion_rate": 0.0026048173504572484
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4516129032258064,
                "recall": 0.3492063492063492,
                "precision": 0.6390041493775933,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005871262778151074,
                "deletion_rate": 0.0013569140642838038
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5766045548654244,
                "recall": 0.48988566402814426,
                "precision": 0.70062893081761,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0002996492993385519,
                "deletion_rate": 0.0005882004764793797
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "vi": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9289586305278176,
                "recall": 0.9292237442922374,
                "precision": 0.9286936679977182,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0021038895324837882,
                "deletion_rate": 0.003049308246448022
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.43883792048929665,
                "recall": 0.3276255707762557,
                "precision": 0.6643518518518519,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005581603036392052,
                "deletion_rate": 0.002358227282875642
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5269606279114288,
                "recall": 0.4587777777777778,
                "precision": 0.6189476840053965,
                "correct_pairwise": 0,
                "hallucination_rate": 0.000306274805068848,
                "deletion_rate": 0.0031161141152080524
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9846368715083799,
                "recall": 0.9791666666666666,
                "precision": 0.9901685393258427,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002263249812880921,
                "deletion_rate": 0.026071925009801475
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5021645021645021,
                "recall": 0.4027777777777778,
                "precision": 0.6666666666666666,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00032458233890214795,
                "deletion_rate": 0.0014701670644391407
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "vi-en": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.36691052335396734,
                "recall": 0.26633986928104575,
                "precision": 0.5895117540687161,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015036998931581655,
                "deletion_rate": 0.0027897590123065964
            }
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3545301069217783,
                "recall": 0.25735294117647056,
                "precision": 0.569620253164557,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0017420913014213881,
                "deletion_rate": 0.0025141544918240487
            }
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "xh": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.7169811320754718,
                "recall": 0.6016119746689695,
                "precision": 0.8870967741935484,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00041418001769678257,
                "deletion_rate": 0.0018198818959404082
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.08455114822546972,
                "recall": 0.046632124352331605,
                "precision": 0.45251396648044695,
                "correct_pairwise": 0,
                "hallucination_rate": 0.022570154304873215,
                "deletion_rate": 0.0006164646382044523
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "yi": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.13601236476043274,
                "recall": 0.07665505226480836,
                "precision": 0.6027397260273972,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0021021810128007807,
                "deletion_rate": 0.0036412778257442096
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.13963636363636361,
                "recall": 0.08362369337979095,
                "precision": 0.42290748898678415,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0025744041814564885,
                "deletion_rate": 0.00460272262745251
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "yo": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.3749139710942877,
                "recall": 0.2582671565722413,
                "precision": 0.6837150925635394,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0015287187127710714,
                "deletion_rate": 0.002537911925498849
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.08054116900961844,
                "recall": 0.04515823159890957,
                "precision": 0.3720703125,
                "correct_pairwise": 0,
                "hallucination_rate": 0.008206772065230922,
                "deletion_rate": 0.0016183244118013196
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.8981636060100168,
                "recall": 0.9405594405594405,
                "precision": 0.8594249201277955,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009426217046249278,
                "deletion_rate": 0.00027366436585885
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.24936386768447835,
                "recall": 0.17132867132867133,
                "precision": 0.45794392523364486,
                "correct_pairwise": 0,
                "hallucination_rate": 0.028903857930189833,
                "deletion_rate": 0.0005817513778322106
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "zh": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.5566265060240964,
                "recall": 0.5164896590273896,
                "precision": 0.6035271064663619,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0009083972239380836,
                "deletion_rate": 0.004396642563860325
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.347143243975088,
                "recall": 0.3583007266629402,
                "precision": 0.33665966386554624,
                "correct_pairwise": 0,
                "hallucination_rate": 0.001234146469553344,
                "deletion_rate": 0.002468292939106688
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.044274637599730306,
                "recall": 0.05400959561343386,
                "precision": 0.037513091497667336,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0038482256164921345,
                "deletion_rate": 0.0019081355963151984
            }
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9579288025889968,
                "recall": 0.9866666666666667,
                "precision": 0.9308176100628931,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00015177577658605687,
                "deletion_rate": 0.00015177577658605687
            }
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4416094210009814,
                "recall": 0.5,
                "precision": 0.3954305799648506,
                "correct_pairwise": 0,
                "hallucination_rate": 0.00010990218705352236,
                "deletion_rate": 0.0
            }
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.9448294981979485,
                "recall": 0.9456159822419534,
                "precision": 0.9440443213296399,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0005581518551454033,
                "deletion_rate": 0.004966605490700622
            }
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.29078014184397166,
                "recall": 0.31853496115427304,
                "precision": 0.2674743709226468,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0010163134017162076,
                "deletion_rate": 0.0008905839087203881
            }
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    },
    "zu": {
        "opus100": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.4245614035087719,
                "recall": 0.2875816993464052,
                "precision": 0.8107202680067002,
                "correct_pairwise": 0,
                "hallucination_rate": 0.002210163156759865,
                "deletion_rate": 0.0031265722705383454
            }
        },
        "opus100-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {
                "f1": 0.15904572564612326,
                "recall": 0.09506833036244801,
                "precision": 0.48632218844984804,
                "correct_pairwise": 0,
                "hallucination_rate": 0.0016853301374480357,
                "deletion_rate": 0.0016291524661997678
            }
        },
        "ted2020-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ud-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "ersatz-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-judgements-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "legal-all-laws-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "code-switching-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences": {
            "meta/meta-llama-3-8b-instruct": {}
        },
        "short-sequences-corrupted-asr": {
            "meta/meta-llama-3-8b-instruct": {}
        }
    }
}